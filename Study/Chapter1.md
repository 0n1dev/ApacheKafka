# 카프카의 역할과 탄생

> 링크드인에서 파폄화된 데이터 수집 및 분배 아키텍처를 운영하는데 큰 어려움을 겪어 이를 해결하기 위해 카프카를 개발.

- 취합된 데이터 스트림을 한 곳에서 실시간으로 관리
- 대용량 데이터 수집 및 실시간 스트림으로 소비
- 일종의 중추 신경 역할

### 카프카의 특징

- 중앙에 배치함으로써 Source Application과 Target Application의 의존도를 최소화 (커플링 완화)
- 생성된 데이터를 어느 타깃으로 보낼지 고민할 필요없이 카프카로 넣으면 됨
- FIFO 방식
- 큐에 데이터를 보내는것은 `프로듀서`, 데이터를 가져가는 것은 `컨슈머`
- 데이터 포맷에는 제한이 없음
    - 직렬화, 역직렬화를 통해 ByteArray로 통신
    - Serializer<T>, Deserializer<T>를 상속받아 커스터마이징 가능

### 카프카의 장점

- 높은 처리량
    - 파티션 단위를 통해 동일 목적의 데이터를 여러 파티션에 분배해서 `병렬`처리 가능
    - 파티션 개수만큼 컨슈머 개수를 늘림
- 확장성
    - 클러스터의 브로커 개수를 늘렸다가 줄였다가 가능
- 영속성
    - 데이터를 메모리에 저장하지 않고 파일 시스템에 저장
    - 페이지 캐시 방식을 활용하여 메모리에 따로 생성
- 고가용성
    - 3개 이상의 서버로 운영시 일부 서버 장애가 발생되어도 무중단으로 데이터 처리
    - 클러스터내에서 복제를 통해 고가용성의 특징을 가짐

-> 2대 이용시 데이터 유실 가능성 있음 3대부터 min.insync.replicas 옵션을 2로 설정 가능

